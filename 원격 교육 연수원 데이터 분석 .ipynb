{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aa1309f",
   "metadata": {},
   "source": [
    "## 아이스크림 연수 후기 크롤링 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca35ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d371f4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('window-size=1920x1080')#크롬드라이버 창크기\n",
    "options.add_argument(\"headless\") #창 숨기기\n",
    "options.add_argument('disable-gpu') #그래픽 성능 낮춰서 크롤링 성능 높아기\n",
    "options.add_argument('lang=ko_KR')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "# driver = wd.Chrome(executable_path=\"/Users/halo8/Desktop/chromedriver\",chrome_options=options)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4530598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_plus ='https://teacher.i-scream.co.kr/help/afterword/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04291e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "\n",
    "urls = []\n",
    "\n",
    "while num < 2:\n",
    "    \n",
    "    \n",
    "    icecream_url = f'https://teacher.i-scream.co.kr/help/afterword/list.do?searchHiddenField=&crsLCode=&crsCode=&searchCondition=&searchKeyword=&pageIndex={num}&sso=ok'\n",
    "    page = requests.get(icecream_url)\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    if page.status_code != 200:\n",
    "        print('오류임')\n",
    "        break\n",
    "\n",
    "    else:\n",
    "\n",
    "#             print('진행시작')\n",
    "\n",
    "        html = page.text\n",
    "        soup = BeautifulSoup( html, 'html.parser')\n",
    "        total = soup.find('tbody')\n",
    "        try :\n",
    "            \n",
    "            for i in total.find_all('tr'):\n",
    "                link = i.find('a')['href']\n",
    "                url = url_plus + link\n",
    "                urls.append(url)\n",
    "\n",
    "            num += 1\n",
    "        \n",
    "        except:\n",
    "            break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03093679",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for u in urls:\n",
    "    driver.get(u)\n",
    "    time.sleep(1)\n",
    "    hs = driver.page_source\n",
    "    soup = BeautifulSoup( hs, 'html.parser')\n",
    "    title =  soup.find('dl','tit_view').text[3:].strip()\n",
    "    text = soup.find('div','view_cont').text.strip()\n",
    "    text1 = text.replace('\\n','')\n",
    "    star = soup.find('span', 'star')['class'][1][-1]\n",
    "    name = soup.find('dl','info_view').text[4:].strip()\n",
    "    date = soup.find_all('dl','info_view1')[1].text.split('등록일')[1].strip()\n",
    "    cate = soup.find_all('dl','info_view1')[0].text.split('분류')[1].strip()\n",
    "    df.append([title,name,text1,star,date,cate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faee4c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(df,columns = ['title','name','text','star','date','category'])\n",
    "# data.to_csv('크롤링.csv',encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b01fe59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285478aa",
   "metadata": {},
   "source": [
    "## 티처빌 연수 후기 크롤링 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e826c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d619550",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('window-size=1920x1080')#크롬드라이버 창크기\n",
    "options.add_argument(\"headless\") #창 숨기기\n",
    "options.add_argument('disable-gpu') #그래픽 성능 낮춰서 크롤링 성능 높아기\n",
    "options.add_argument('lang=ko_KR')\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6245ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "cnt = 1\n",
    "stop = 1\n",
    "\n",
    "url = 'https://www.teacherville.co.kr/trainguide/review/reviewList.edu'\n",
    "driver.get(url)\n",
    "\n",
    "hs = driver.page_source\n",
    "soup = BeautifulSoup( hs, 'html.parser')\n",
    "h = soup.find('ul',{'id':'reviewResultList'})\n",
    "\n",
    "for i in h.find_all('li'):\n",
    "    date = i.find('span','day').text\n",
    "    hour = i.find('strong','credit').text\n",
    "    name = i.find_all('p')[1].text.split(']')[1].strip()\n",
    "    cate = i.find_all('p')[1].text.split(']')[0].split('/')[1].strip()\n",
    "    text = i.find('p','text on').text.strip()\n",
    "    star = len(i.find_all('span','star on'))\n",
    "    df.append([hour,name,text,star,cate,date])\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "while stop < 2:\n",
    "    \n",
    "    if cnt==1:\n",
    "\n",
    "        li=[1,2,3,4,5,6,7,8,9,10]\n",
    "        cnt+=1\n",
    "\n",
    "    else:\n",
    "        li=[3,4,5,6,7,8,9,10,11,12]\n",
    "\n",
    "    for num in li:\n",
    "        \n",
    "        \n",
    "        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "        driver.find_element(by='xpath', value= f'''//*[@id=\"divPaging\"]/a[{num}]''').click()\n",
    "        time.sleep(3)\n",
    "\n",
    "        hs = driver.page_source\n",
    "        soup = BeautifulSoup( hs, 'html.parser')\n",
    "        h = soup.find('ul',{'id':'reviewResultList'})\n",
    "        \n",
    "        \n",
    "        if date.split('/')[:2] == ['2021', '9']:\n",
    "            print('멈춤')\n",
    "            stop += 1\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "\n",
    "            for i in h.find_all('li'):\n",
    "                date = i.find('span','day').text\n",
    "                hour = i.find('strong','credit').text\n",
    "                name = i.find_all('p')[1].text.split(']')[1].strip()\n",
    "                cate = i.find_all('p')[1].text.split(']')[0].split('/')[1].strip()\n",
    "                text = i.find('p','text on').text.strip()\n",
    "                star = len(i.find_all('span','star on'))\n",
    "                df.append([hour,name,text,star,cate,date])\n",
    "\n",
    "#     if date.split('/')[2] == '22':\n",
    "#         stop += 1\n",
    "#         break\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# //*[@id=\"divPaging\"]/a[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacc34f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3bc016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
